{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_processing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(key) -> int:\n",
    "    with open('./conf/config.yaml') as file:\n",
    "        file = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    return file[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config('CONFIG')\n",
    "paths = get_config('PATHS')\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_processing.load_images(paths['BASE_PATH']+'train')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) = data_processing.make_pairs(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATCH OUT !!! - this can print way too many images :)\n",
    "# 0 - for negatives\n",
    "# 1 - for positives \n",
    "# data_processing.show_positive_train(X_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processing.pairs_montage(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Lambda, Flatten\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Convolution2D, Dropout, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=None):\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias(shape, dtype=None):\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(input_shape):\n",
    "\n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    kernel_size = 3\n",
    "    # CNN\n",
    "    model = Sequential()\n",
    "    # input layer\n",
    "    model.add(Conv2D(32, (5,5), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid'))\n",
    "\n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "\n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1, activation='sigmoid')(L1_distance)\n",
    "\n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
    "\n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_siamese_model(config['IMG_SHAPE'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=config['LEARNING_RATE'])\n",
    "model.compile(loss=tfa.losses.ContrastiveLoss(), optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.expand_dims(X, axis=-1)\n",
    "(X_train, y_train) = data_processing.make_pairs(trainX, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "\t[X_train[:, 0], X_train[:, 1]], y_train[:],\n",
    "\tvalidation_split=config['VALIDATION_SPLIT'],\n",
    "\tbatch_size=config['BATCH_SIZE'], \n",
    "\tepochs=config['EPOCHS'],\n",
    "\tverbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(paths['MODEL_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.plot(model.history.history['loss'][:], label='loss')\n",
    "plt.plot(model.history.history['val_loss'][:], label='val_Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.scandir(paths['BASE_PATH']+paths['TEST_SAMPLES']):\n",
    "    if filename.is_file() and '.DS_Store' not in filename.path:\n",
    "        sample_name = filename.path\n",
    "        data_processing.evaluate_data(model, paths['BASE_PATH']+paths['TEST_CLASSES'], sample_name,)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
