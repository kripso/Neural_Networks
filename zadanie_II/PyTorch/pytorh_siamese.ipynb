{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P-sHhT87oXfd"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "# import wandb\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from itertools import permutations\n",
        "from pytorch_metric_learning import losses\n",
        "import random\n",
        "# from torchsummaryX import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(img, text=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "        \n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "    \n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()\n",
        "\n",
        "def show_pair(img1, img2, description, label = None):\n",
        "    concatenated = torch.cat((img1, img2), 0)\n",
        "    concatenated = torchvision.utils.make_grid(concatenated)\n",
        "\n",
        "    if label:\n",
        "        truth = '' if label else ' not'\n",
        "        imshow(concatenated, f'is{truth} the same person')\n",
        "    else:\n",
        "        imshow(concatenated, description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = 'cpu'\n",
        "print(device)\n",
        "\n",
        "progres_print_rate = 10\n",
        "\n",
        "config = {\n",
        "  'batch_size': 256,\n",
        "  'epochs': 100,\n",
        "  'learning_rate': 0.00003,\n",
        "  'contrastive_loss_margin': 1,\n",
        "  'pin_memory': False,\n",
        "  'num_workers': 0,\n",
        "  'model_path': '../data/model/',\n",
        "}\n",
        "\n",
        "# wandb.init(project=\"my-test-project\")\n",
        "\n",
        "# wandb_config = {\n",
        "#   'batch_size': config['batch_size'],\n",
        "#   'epochs': config['epochs'],\n",
        "#   'learning_rate': config['learning_rate'],\n",
        "# }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "# One positie one negative for each image\n",
        "#\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.images_perm = list(permutations(imageFolderDataset.imgs,2))\n",
        "        self.images = imageFolderDataset.imgs\n",
        "        self.transform = transform\n",
        "        self.index = 0\n",
        "        \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        _tmp0 = self.images[self.index]\n",
        "    \n",
        "        iteration = index % 2\n",
        "        self.index += iteration\n",
        "        \n",
        "        if iteration:\n",
        "            while True:\n",
        "                #Look untill the same class image is found\n",
        "                _tmp1 = random.choice(self.images) \n",
        "                if _tmp0[1] == _tmp1[1] and _tmp0[0] != _tmp1[0]:\n",
        "                    break\n",
        "        else:\n",
        "            while True:\n",
        "                #Look untill a different class image is found\n",
        "                _tmp1 = random.choice(self.images) \n",
        "                if _tmp0[1] != _tmp1[1]:\n",
        "                    break\n",
        "        \n",
        "        img0 = Image.open(_tmp0[0])\n",
        "        img1 = Image.open(_tmp1[0])\n",
        "\n",
        "        # img0 = img0.convert(\"L\")\n",
        "        # img1 = img1.convert(\"L\")\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "            \n",
        "        # Image 1, Image2, Label\n",
        "        return img0, img1, torch.from_numpy(np.array([int(_tmp0[1] == _tmp1[1])], dtype=np.float64))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return (len(self.images) * 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "# 50:50 chance\n",
        "#\n",
        "class SiameseNetworkDatasetChance(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.images_perm = list(permutations(imageFolderDataset.imgs,2))\n",
        "        self.images = imageFolderDataset.imgs\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        _tmp0 = self.images[index]\n",
        "        \n",
        "        # ensure 50:50 chance of getting positive and negative pair\n",
        "        should_get_same_class = random.randint(0,1)\n",
        "        if should_get_same_class:\n",
        "            while True:\n",
        "                #Look untill the same class image is found\n",
        "                _tmp1 = random.choice(self.images) \n",
        "                if _tmp0[1] == _tmp1[1] and _tmp0[0] != _tmp1[0]:\n",
        "                    break\n",
        "        else:\n",
        "            while True:\n",
        "                #Look untill a different class image is found\n",
        "                _tmp1 = random.choice(self.images) \n",
        "                if _tmp0[1] != _tmp1[1]:\n",
        "                    break\n",
        "        \n",
        "        img0 = Image.open(_tmp0[0])\n",
        "        img1 = Image.open(_tmp1[0])\n",
        "\n",
        "        # img0 = img0.convert(\"L\")\n",
        "        # img1 = img1.convert(\"L\")\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        \n",
        "        # Image 1, Image2, Label\n",
        "        return img0, img1, torch.from_numpy(np.array([int(_tmp0[1] == _tmp1[1])], dtype=np.float64))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "# Permutations\n",
        "# \n",
        "class SiameseNetworkDatasetPerm(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.images_perm = list(permutations(imageFolderDataset.imgs,2))\n",
        "        self.images = imageFolderDataset.imgs\n",
        "        self.transform = transform   \n",
        "    \n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        img_tuple = self.images_perm[index]\n",
        "        \n",
        "        _tmp0 = img_tuple[0]\n",
        "        _tmp1 = img_tuple[1]\n",
        "        \n",
        "        img0 = Image.open(_tmp0[0])\n",
        "        img1 = Image.open(_tmp1[0])\n",
        "\n",
        "        # img0 = img0.convert(\"L\")\n",
        "        # img1 = img1.convert(\"L\")\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "            \n",
        "        return img0, img1, torch.from_numpy(np.array([int(_tmp0[1] == _tmp1[1])], dtype=np.float64))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images_perm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Qn5Wss2MoyWN"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.Resize((64,64)),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "imageFolderDataset = datasets.ImageFolder('../data/faces/training', transform=transform)\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=imageFolderDataset, transform=transform)\n",
        "\n",
        "train_dataset, val_dataset = train_test_split(siamese_dataset,  test_size = 0.2, shuffle=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], num_workers = config['num_workers'], pin_memory=config['pin_memory'], shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_batch = next(iter(train_dataloader))\n",
        "\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1]),0)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy().reshape(-1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "945XnSQ9Ok3k"
      },
      "outputs": [],
      "source": [
        "#create the Siamese Neural Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        \n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=10,bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(64, 128, kernel_size=7,bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(128, 128, kernel_size=4,bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "                        \n",
        "            nn.Conv2d(128, 256, kernel_size=3,bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Setting up the Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(4096, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(512,1)\n",
        "        )\n",
        "        \n",
        "    def _forward(self, x):\n",
        "\n",
        "        output = self.cnn(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "\n",
        "        output1 = self._forward(input1)\n",
        "        output2 = self._forward(input2)\n",
        "        \n",
        "        return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create the Siamese Neural Network\n",
        "class SiameseNetworkSteve(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetworkSteve, self).__init__()\n",
        "        \n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=5),\n",
        "            # nn.BatchNorm2d(64), \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(2,2),\n",
        "            nn.Dropout2d(0.2),\n",
        "            \n",
        "            # nn.MaxPool2d(2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(64, 128, kernel_size=4),\n",
        "            # nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(2,2),\n",
        "            nn.Dropout2d(0.2),\n",
        "\n",
        "            # nn.MaxPool2d(2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(128, 128, kernel_size=3),\n",
        "            # nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(2,2),\n",
        "            nn.Dropout2d(0.2),\n",
        "\n",
        "            # nn.MaxPool2d(2, stride=2),\n",
        "                        \n",
        "            nn.Conv2d(128, 256, kernel_size=3),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(2,2),\n",
        "            nn.Dropout2d(0.2),\n",
        "            \n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Setting up the Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(256, 4096),\n",
        "            \n",
        "            nn.Sigmoid(),\n",
        "            \n",
        "            nn.Linear(4096,1),\n",
        "            \n",
        "            # nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "    def _forward(self, x):\n",
        "\n",
        "        output = self.cnn(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "\n",
        "        output1 = self._forward(input1)\n",
        "        output2 = self._forward(input2)\n",
        "        \n",
        "        return output1, output2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Contrastive Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Contrastive Loss Function\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=config['contrastive_loss_margin']):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        # Calculate the euclidian distance and calculate the contrastive loss\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "        \n",
        "        loss_contrastive = torch.mean((label) * torch.pow(euclidean_distance, 2) +\n",
        "                                        (1-label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        \n",
        "        return loss_contrastive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "colab_type": "code",
        "id": "8d4fbAy0PAvb",
        "outputId": "9423589c-0cef-44ae-dc2c-2d58af7489e5"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "net = SiameseNetworkSteve().to(device)\n",
        "loss_fun = ContrastiveLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = config['learning_rate'] )\n",
        "\n",
        "# shape = tuple(next(iter(train_dataloader))[0].shape)\n",
        "# input_shape = torch.zeros(shape)\n",
        "# summary(net,input_shape,input2=input_shape)\n",
        "# train_dataloader\n",
        "# print(tuple(next(iter(train_dataloader))[0].shape)[1:])\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8rvo05ug2LyP"
      },
      "outputs": [],
      "source": [
        "counter = []\n",
        "loss_history = [] \n",
        "val_loss_history = [] \n",
        "\n",
        "def validate_model(dataloader, model, loss_fun):                       \n",
        "    running_loss = 0.0\n",
        "    model.eval()      \n",
        "    with torch.no_grad():\n",
        "        for index, (data1, data2, label) in enumerate(dataloader, 0):\n",
        "            data1, data2, label = data1.to(device), data2.to(device), label.to(device)\n",
        "\n",
        "            output1, output2 = model(data1, data2)\n",
        "            loss = loss_fun(output1, output2, label)\n",
        "            running_loss = running_loss + loss.item()\n",
        "               \n",
        "            # wandb.log({\"val_loss\": running_loss})\n",
        "            # wandb.watch(model)\n",
        "            \n",
        "        return running_loss\n",
        "def save_model():\n",
        "    pass    \n",
        "def learn_model(model, loss_fun, optimizer, train_dataloader, val_dataloader, num_epochs = config['epochs']):\n",
        "    iteration_number= 0\n",
        "    # Iterate throught the epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Iterate over batches\n",
        "        for index, (data1, data2, label) in enumerate(train_dataloader, 0):\n",
        "            # Send the images and labels to CUDA\n",
        "            data1, data2, label = data1.to(device), data2.to(device), label.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Pass in the two images into the network and obtain two outputs\n",
        "            output1, output2 = model(data1, data2)\n",
        "\n",
        "            # Pass the outputs of the networks and label into the loss function\n",
        "            loss = loss_fun(output1, output2, label)\n",
        "\n",
        "            # Calculate the backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Optimize\n",
        "            optimizer.step()\n",
        "            \n",
        "            # wandb.log({\"loss\": loss})\n",
        "            # wandb.watch(model)\n",
        "            \n",
        "            # Every 10 batches save the loss\n",
        "            if index % 10 == 0 :\n",
        "                iteration_number += 1\n",
        "                \n",
        "                val_loss = validate_model(dataloader=val_dataloader, model=model, loss_fun=loss_fun)\n",
        "                \n",
        "                counter.append(iteration_number)\n",
        "                loss_history.append(loss.item())\n",
        "                val_loss_history.append(val_loss)\n",
        "       \n",
        "        # Every progres_print_rate epoch repoty the loss and val_loss\n",
        "        if (epoch + 1) % progres_print_rate == 0 :\n",
        "            print(f'Epoch number {epoch + 1}')\n",
        "            print(f'\\tCurrent loss {loss.item()}')\n",
        "            print(f'\\tValidation Loss: {val_loss}')\n",
        "            print('-----------------------------------------------------------')\n",
        "            torch.save({\n",
        "                'epoch':epoch+1,\n",
        "                'model_state_dict': net.state_dict(),\n",
        "                'optimizer_state_dict':optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "            }, config['model_path'] + f'model_{epoch+1}.pt')\n",
        "            \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "learn_model(net, loss_fun, optimizer, train_dataloader, val_dataloader, config['epochs'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(counter, loss_history,label = \"loss\")\n",
        "plt.plot(counter, val_loss_history,label = \"val_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "torch.save(net.state_dict(), config['model_path'] + 'model.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checkpoint = torch.load(config['model_path'] + 'model_100.pt')\n",
        "# net.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "# net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net.load_state_dict(torch.load(config['model_path'] + 'model.pt'))\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "# folder_dataset_test = datasets.ImageFolder(root=\"./data/faces2/testing/\")\n",
        "# siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
        "#                                         transform=transform)\n",
        "# test_dataloader = DataLoader(siamese_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# for i in range(21):\n",
        "#     lowest_eu = []\n",
        "#     lowest_conc = []\n",
        "#     # Grab one image that we are going to test\n",
        "#     dataiter = iter(test_dataloader)\n",
        "#     x0, _, _ = next(dataiter)\n",
        "\n",
        "#     for i in range(20):\n",
        "#         # Iterate over 10 images and test them with the first image (x0)\n",
        "#         _, x1, label2 = next(dataiter)\n",
        "\n",
        "#         # Concatenate the two images together\n",
        "#         concatenated = torch.cat((x0, x1), 0)\n",
        "#         concatenated = torchvision.utils.make_grid(concatenated)\n",
        "#         # print(concatenated.type)\n",
        "#         output1, output2 = net(x0.to(device), x1.to(device))\n",
        "#         euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "\n",
        "#         if euclidean_distance.item() > float(0.05):\n",
        "#             lowest_eu.append(euclidean_distance.item())\n",
        "#             lowest_conc.append(concatenated)\n",
        "            \n",
        "#     euclidean_distance=lowest_eu[lowest_eu.index(min(lowest_eu))]\n",
        "#     concatenated=lowest_conc[lowest_eu.index(min(lowest_eu))]\n",
        "#     imshow(concatenated, f'Dissimilarity: {euclidean_distance:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_dataset_test = datasets.ImageFolder(root=\"../data/faces/testing/\")\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
        "                                        transform=transform)\n",
        "test_dataloader = DataLoader(siamese_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(test_dataloader)\n",
        "\n",
        "for x0, x1, label2 in dataiter:\n",
        "    # Iterate over 10 images and test them with the first image (x0)\n",
        "    \n",
        "    output1, output2 = net(x0.to(device), x1.to(device))\n",
        "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "\n",
        "    show_pair(x0, x1, f'Dissimilarity: {euclidean_distance.item():.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Linear_regression_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
